{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the raw modis data\n",
    "\n",
    "- I am using the conda environment version 21.10 http://climate-cms.wikis.unsw.edu.au/Conda#21.10\n",
    "- MODIS data has been downloaded from: https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/61/MCD06COSP_D3_MODIS/\n",
    "\n",
    "### In this notebook: \n",
    "- Pull out fields of interest and regrid onto ACCESS grid, and offset time by 12 hrs to match ACCESS too.  \n",
    "- For the histograms, sum the total and partly cloudy total fields \n",
    "- Rename dimensions to match the ACCESS names, and variables so that ACCESS & modis will match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "sys.path.append('/home/563/slf563/code/gadi/jk72/ACCESS-CM2_analysis/COSP_analysis/Clustering_paper')\n",
    "from functions import create_time\n",
    "from calendar import monthrange, isleap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_grid = xr.open_mfdataset('/g/data/jk72/slf563/ACCESS/fx/sftlf_fx_ACCESS-CM2_amip_r1i1p1f1_gn.nc') # ACCESS grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "fout = '/g/data/p66/slf563/OBS/MCD06COSP_D3_MODIS/'\n",
    "\n",
    "for yr in range(2015,2020):\n",
    "    time = create_time('{}-01-01'.format(yr),'{}-12-31'.format(yr),'D')\n",
    "    fdir = '/g/data/p66/slf563/OBS/MCD06COSP_D3_MODIS/{}/'.format(yr)\n",
    "    dims = xr.open_mfdataset(fdir+'001/*.nc')\n",
    "\n",
    "    if isleap(yr): ndays = 366\n",
    "    else: ndays = 365\n",
    "    print(yr)\n",
    "    for day in range(0,ndays): \n",
    "        \n",
    "        h = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Optical_Thickness_Total')\n",
    "        h = h.assign_coords({'time':time[day]})\n",
    "        h = h.expand_dims('time')\n",
    "\n",
    "        h2 = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Optical_Thickness_PCL_Total')\n",
    "        h2 = h2.assign_coords({'time':time[day]})\n",
    "        h2 = h2.expand_dims('time')  \n",
    "        \n",
    "        # sum cloudy and partly cloudy \n",
    "        h.JHisto_vs_Cloud_Top_Pressure.values = h2.JHisto_vs_Cloud_Top_Pressure.values + h.JHisto_vs_Cloud_Top_Pressure.values\n",
    "        del h2\n",
    "        h = h.JHisto_vs_Cloud_Top_Pressure.to_dataset()\n",
    "        \n",
    "        ctp = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Top_Pressure')\n",
    "        ctp = ctp.assign_coords({'time':time[day]})\n",
    "        ctp = ctp.expand_dims('time') \n",
    "        ctp = ctp[['Mean','Standard_Deviation']]\n",
    "        ctp = ctp.rename({'Mean':'CTP','Standard_Deviation':'CTP_StD'})\n",
    "        \n",
    "        lwp = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Water_Path_Liquid')\n",
    "        lwp = lwp.assign_coords({'time':time[day]})\n",
    "        lwp = lwp.expand_dims('time')\n",
    "        lwp = lwp[['Mean','Standard_Deviation']]\n",
    "        lwp = lwp.rename({'Mean':'LWP','Standard_Deviation':'LWP_StD'})\n",
    "        \n",
    "        iwp = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Water_Path_Ice')\n",
    "        iwp = iwp.assign_coords({'time':time[day]})\n",
    "        iwp = iwp.expand_dims('time') \n",
    "        iwp = iwp[['Mean','Standard_Deviation']]\n",
    "        iwp = iwp.rename({'Mean':'IWP','Standard_Deviation':'IWP_StD'})\n",
    "        \n",
    "        taul = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Optical_Thickness_Liquid')\n",
    "        taul = taul.assign_coords({'time':time[day]})\n",
    "        taul = taul.expand_dims('time') \n",
    "        taul = taul[['Mean','Standard_Deviation']]\n",
    "        taul = taul.rename({'Mean':'TauL','Standard_Deviation':'TauL_StD'})        \n",
    "        \n",
    "        taui = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Optical_Thickness_Ice')\n",
    "        taui = taui.assign_coords({'time':time[day]})\n",
    "        taui = taui.expand_dims('time') \n",
    "        taui = taui[['Mean','Standard_Deviation']]\n",
    "        taui = taui.rename({'Mean':'TauI','Standard_Deviation':'TauI_StD'})  \n",
    "        \n",
    "        cfi = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Retrieval_Fraction_Ice')\n",
    "        cfi = cfi.assign_coords({'time':time[day]})\n",
    "        cfi = cfi.expand_dims('time') \n",
    "        cfi = cfi[['Mean','Standard_Deviation']]\n",
    "        cfi = cfi.rename({'Mean':'CFI','Standard_Deviation':'CFI_StD'})  \n",
    "        \n",
    "        cfl = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Retrieval_Fraction_Liquid')\n",
    "        cfl = cfl.assign_coords({'time':time[day]})\n",
    "        cfl = cfl.expand_dims('time') \n",
    "        cfl = cfl[['Mean','Standard_Deviation']]\n",
    "        cfl = cfl.rename({'Mean':'CFL','Standard_Deviation':'CFL_StD'})\n",
    "        \n",
    "        cf = xr.open_mfdataset(fdir+'{:03d}/*.nc'.format(day+1),\n",
    "                        group='Cloud_Retrieval_Fraction_Total')\n",
    "        cf = cf.assign_coords({'time':time[day]})\n",
    "        cf = cf.expand_dims('time') \n",
    "        cf = cf[['Mean','Standard_Deviation']]\n",
    "        cf = cf.rename({'Mean':'CF','Standard_Deviation':'CF_StD'})        \n",
    "        \n",
    "        \n",
    "        c = xr.merge([ctp,lwp,iwp,taul,taui,cfl,cfi,cf]) # merge all the cloud fields into one file \n",
    "        \n",
    "        if time[day].day == 1: \n",
    "            histo = h.copy()\n",
    "            clouds = c.copy()\n",
    "        else: \n",
    "            histo = histo.merge(h)\n",
    "            clouds = clouds.merge(c)\n",
    "            \n",
    "        if time[day].day == monthrange(yr, time[day].month)[1]:\n",
    "            \n",
    "            histo = histo.assign_coords({'latitude':dims.latitude})\n",
    "            histo = histo.assign_coords({'longitude':(dims.longitude)%360}).sortby('longitude')\n",
    "            histo = histo.rename({'latitude':'lat',\n",
    "                                'longitude':'lon'})\n",
    "            histo = histo.interp(lat=access_grid.lat,lon=access_grid.lon)\n",
    "            histo['time'] = histo.time + np.timedelta64(12,'h')\n",
    "            histo = histo.rename({'jhisto_cloud_optical_thickness_total_7':'tau',\n",
    "                                       'jhisto_cloud_top_pressure_7':'pressure',\n",
    "                                       })\n",
    "            histo = histo.rename({'JHisto_vs_Cloud_Top_Pressure':'histo'})\n",
    "            histo.attrs = h.JHisto_vs_Cloud_Top_Pressure.attrs\n",
    "            histo = histo.transpose('tau','pressure','time','lat','lon',)\n",
    "            histo.to_netcdf(fout+'MCD06COSP_D3_MODIS.{}{:02d}_histos.nc'.format(yr,time[day].month))\n",
    "\n",
    "            clouds = clouds.assign_coords({'latitude':dims.latitude})\n",
    "            clouds = clouds.assign_coords({'longitude':(dims.longitude)%360}).sortby('longitude')\n",
    "            clouds = clouds.rename({'latitude':'lat',\n",
    "                                'longitude':'lon'})\n",
    "            clouds = clouds.interp(lat=access_grid.lat,lon=access_grid.lon)\n",
    "            clouds['time'] = clouds.time + np.timedelta64(12,'h')\n",
    "            clouds.to_netcdf(fout+'MCD06COSP_D3_MODIS.{}{:02d}_cloud.nc'.format(yr,time[day].month))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
